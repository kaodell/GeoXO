# -*- coding: utf-8 -*-
"""AirNow_2020_DailyAreaMeanMax.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MxZWdo-1A-B2jtetduHPJrqLpUfPYaNH

# AirNow Surface Reporting Area File

---
    author: Barron H. Henderson
    date: 2023-03-16
    last updated: 2023-03-16
---

This notebook produces a CSV with daily records for each Reporting Area in AirNow. The reporting area has multiple monitors reporting to it each day. This notebook reports the mean and maximum value from monitors within the reporting area. It does so by joining the `daily_data_v2.dat` and `Site_To_ReportingArea.dat` files from AirNow. Then, it groups by day and reporting area.

05.09.2023
This code was modifed by Katelyn O'Dell to assign reporting area values by zip code, remove hourly calculations
unused for this application, and add additional commenting
"""
# define local paths
kate_out_path = '/Users/kodell/Desktop/'
zip_codes_shp_fn = '/Users/kodell/Library/CloudStorage/GoogleDrive-kodell@email.gwu.edu/My Drive/Ongoing Projects/GeoXO/population_data/ACS_IPUMS/2020pop_2010zctas/nhgis0011_shape/nhgis0011_shapefile_tl2020_us_zcta_2010/US_zcta_2010_tl20.shp'
state_shp_fn = '/Users/kodell/Library/CloudStorage/GoogleDrive-kodell@email.gwu.edu/My Drive/Ongoing Projects/GeoXO/health_data/cb_2018_us_state_500k.zip'

# import modules
import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt
import geopandas as gpd

hrs = list(range(0, 24))

# create array of dates
dates = pd.date_range('2020-01-01', '2020-12-31', freq='d')
# url where airnow files are available
urlroot = 'https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow'
dailydfs = []
hdfs = []
rdfrows = []
maxr = 0
# loop through dates and pull airnow data
for date in dates:
  print(f'{date:%Y-%m-%d}', end='.')
  s2radf = pd.read_csv(f'{urlroot}/{date:%Y/%Y%m%d}/Site_To_ReportingArea.csv', encoding='latin1')
  dvdf = pd.read_csv(f'{urlroot}/{date:%Y/%Y%m%d}/daily_data_v2.dat', delimiter='|', names='Valid date|AQSID|site name|parameter name|reporting units|value|averaging period|data source|AQI|AQICategory|latitude|longitude|fullaqsid'.split('|'))
  # merge reporting area and daily data files
  dailydf = dvdf.merge(s2radf, left_on='AQSID', right_on='SiteID')
  dailydf['date'] = date
  dailydfs.append(dailydf)
print()
dailydf = pd.concat(dailydfs)
dailydf.min()

# find mean and max daily values by reporting areas
radf = dailydf.groupby(['ReportingAreaID', 'parameter name', 'Valid date']).agg(
    ReportingAreaName=('ReportingAreaName', 'first'),
    ReportingAreaState=('ReportingAreaState', 'first'),
    ReportingAreaLong=('ReportingAreaLong', 'mean'),
    ReportingAreaLat=('ReportingAreaLat', 'mean'),
    max_value=('value', 'max'), mean_value=('value', 'mean')
)
# write to csv
radf.to_csv(kate_out_path+'Reporting_daily_data_v2.dat')

# pull conus data for plotting
conus = [k for k in sorted(radf['ReportingAreaState'].unique()) if k not in ('  ', 'AK', 'HI', 'MX', 'CN', 'PR')]
# pull single day for plotting
plotdf = radf.query(f'`parameter name` == "PM2.5-24hr" and ReportingAreaState in {conus} and  `Valid date` == "01/01/20"')
plotdf.plot.scatter(x='ReportingAreaLong', y='ReportingAreaLat', c='max_value', cmap='viridis', vmax=30)
radf.query(f'ReportingAreaState in {conus} and   `Valid date` == "01/01/20"').sort_values(by='ReportingAreaLat')

# Commented out IPython magic to ensure Python compatibility.
# %pip install pyproj pycno

"""# This part makes a map"""
# create gridded map of pm values using reporting area assignments (not used in O'Dell et al. apart from checking
# below version with zipcode assignments for compatability)
from sklearn.neighbors import NearestNeighbors
import pycno
import pyproj

lon = np.linspace(-135, -55, 8000)
lat = np.linspace(20, 55, 3500)
LON, LAT = np.meshgrid(lon, lat)
griddf = pd.DataFrame(dict(lon=LON.ravel(), lat=LAT.ravel()))

proj = pyproj.Proj(
    (
      '+proj=lcc +lat_0=40 +lon_0=-97 +lat_1=33 +lat_2=45 '
      + '+x_0=2412000 +y_0=1620000 +R=6370000 '
      + '+no_defs'
    ), preserve_units=True
)
cno = pycno.cno(proj=proj)

griddf.loc[:,'X'], griddf.loc[:,'Y'] = proj(griddf['lon'], griddf['lat'])
plotdf.loc[:,'X'], plotdf.loc[:,'Y'] = proj(plotdf['ReportingAreaLong'], plotdf['ReportingAreaLat'])

nn = NearestNeighbors()
nn.fit(plotdf[['X', 'Y']].values)

dist, idx = nn.kneighbors(griddf[['X', 'Y']].values, n_neighbors=1)

griddf['idx'] = idx[:, 0]
griddf['dist2nearest'] = dist

griddf['PM25_MAX'] = plotdf.iloc[idx[:, 0]]['max_value'].values
griddf['PM25_MEAN'] = plotdf.iloc[idx[:, 0]]['mean_value'].values

gridds = griddf.set_index(['lat', 'lon']).to_xarray()
fig, ax= plt.subplots(figsize=(12, 6))
gridds['PM25_MAX'].where(
    gridds['dist2nearest'] < (50 * 1609.34) # convert 50 miles to meters
).plot(vmin=0, vmax=30, ax=ax)
pycno.cno().drawstates()

np.diff(gridds['X'][0]).max()

np.diff(gridds['Y'][:, 0]).max()

#%% section added by Kate O'Dell to assign values to the zipcodes, much of this adapted from
#   code written by Barron H. Henderson, AirNowEquivalent.pdf, availble in this github repository

# load zipcode shape file and allign projections
statedf = gpd.read_file(state_shp_fn)
zipdf1 = gpd.read_file(zip_codes_shp_fn)
zipdfproj = zipdf1.to_crs(proj.srs)
zipdf = zipdf1.to_crs(statedf.crs)
zipdf.loc[:,'X'], zipdf.loc[:,'Y'] = zipdfproj.geometry.centroid.x, zipdfproj.geometry.centroid.y

zipstatedf = gpd.sjoin(zipdf, statedf).reset_index()
zipstatedf['STUSPS']=zipstatedf['STUSPS'].astype('string')
# pull pm from radf file we just made
radf_in = pd.read_csv(kate_out_path+'Reporting_daily_data_v2.dat')
pm_radf = radf_in[radf_in['parameter name'] == 'PM2.5-24hr']
pm_radf.loc[:,'X'], pm_radf.loc[:,'Y'] = proj(pm_radf['ReportingAreaLong'].values, pm_radf['ReportingAreaLat'].values)

for date in pd.date_range('2020-01-01', '2020-12-31'):
    # pull data for date
    pm_radf_day = pm_radf[pm_radf['Valid date']==f'{date:%m/%d/%y}']
    pm_radf_day.reset_index(inplace=True)
    # create nearest neighbors function
    othnn = NearestNeighbors()
    othnn.fit(pm_radf_day[['X', 'Y']].values)
    othdist, othidx = othnn.kneighbors(zipstatedf[['X', 'Y']].values, n_neighbors=1) 
    # write nearest values to zipstatedf dataframe
    zipstatedf['OTH_max_value'] = pm_radf_day.iloc[othidx[:, 0]]['max_value'].values 
    zipstatedf['OTH_mean_value'] = pm_radf_day.iloc[othidx[:, 0]]['mean_value'].values 
    zipstatedf['OTH_DIST'] = othdist[:, 0]
    
    special_states = ("MD", "NY", "MA", "VT", "NH", "ME", "NJ")
    
    zipstatedf['STATE_max_value'] = np.nan
    zipstatedf['STATE_mean_value'] = np.nan
    zipstatedf['STATE_DIST'] = np.nan
    for st in special_states: # see header for AirNowEquivalent.pdf for a description of special states
        stnn = NearestNeighbors()
        stmaxdf = pm_radf_day.query(f'`ReportingAreaState` == "{st}"')
        if stmaxdf.shape[0]==0:
            print(st, 'has no valid values')
            continue
        sttgtdf = zipstatedf.query(f'STUSPS == "{st}"') 
        stnn.fit(stmaxdf[['X', 'Y']].values)
        stdist, stidx = stnn.kneighbors(sttgtdf[['X', 'Y']].values,n_neighbors=1)
        zipstatedf.loc[sttgtdf.index, 'STATE_max_value'] = stmaxdf['max_value'].iloc[stidx[:, 0]].values
        zipstatedf.loc[sttgtdf.index, 'STATE_mean_value'] = stmaxdf['mean_value'].iloc[stidx[:, 0]].values
        zipstatedf.loc[sttgtdf.index, 'STATE_DIST'] = stdist[:, 0]
        
    zipstatedf['FINAL_max_value'] = np.nan
    zipstatedf['FINAL_mean_value'] = np.nan
    # Counts when coordinate is not in a special state, where the monitor is within 50 miles
    isoth = (~zipstatedf['STUSPS'].isin(special_states)) & (zipstatedf['OTH_DIST'] < 80.4672e3)# & (~tgtdf['STUSPS'].isna())
    zipstatedf.loc[isoth, 'FINAL_max_value'] = zipstatedf.loc[isoth, 'OTH_max_value']
    zipstatedf.loc[isoth, 'FINAL_mean_value'] = zipstatedf.loc[isoth, 'OTH_mean_value']
    # Counts when is in the special_states list
    isstate = (zipstatedf['STUSPS'].isin(special_states))
    zipstatedf.loc[isstate, 'FINAL_max_value'] = zipstatedf.loc[isstate, 'STATE_max_value'] 
    zipstatedf.loc[isstate, 'FINAL_mean_value'] = zipstatedf.loc[isstate, 'STATE_mean_value'] 
    # write to file
    zippath = kate_out_path + f'airnowlike_daily/{date:%Y}/ZIP_daily_{date:%Y%m%d}.csv'
    os.makedirs(os.path.dirname(zippath), exist_ok=True) 
    zipstatedf[['GEOID10', 'STUSPS', 'OTH_DIST', 
                'OTH_max_value','STATE_max_value','OTH_mean_value','STATE_mean_value', 
                'STATE_DIST', 'FINAL_max_value','FINAL_mean_value']].to_csv(zippath,index=False)
    print(date)

# plot to check
zip_plot = zipdf[['GEOID10', 'geometry']].merge(
    pd.read_csv(kate_out_path + 'airnowlike_daily/2020/ZIP_daily_20200101.csv',
                dtype=dict(GEOID10='str')), left_on='GEOID10', right_on='GEOID10')
ax = zip_plot.plot('FINAL_max_value', edgecolor='none',aspect='auto',vmin=0, vmax=30)
plt.xlim(-130, -60)
plt.ylim(20, 50)
pycno.cno().drawstates()
ax.set_aspect(6/4)     
